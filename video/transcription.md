00:00:00 Just hours ago, yet another deep-thinking large language model hit the timeline, 00:00:04 crushing existing benchmarks and reaching the coveted number one spot on the LM Arena leaderboard. 00:00:09 This new model is none other than Elon's based in red-pilled Groch 3. 00:00:13 Not only is it smart as hell, but it's also mostly uncensored, 00:00:16 and will generate content that's illegal in many parts of the world. 00:00:19 It has a deep-thinking mode like Deep-Car 1. 00:00:21 It can apparently do text a video, 00:00:23 and in the near future, we'll have a paid subscription for something even more powerful called SuperGroc. 00:00:28 I'm already paying for Twitter Premium Plus just to access GROC 3, so that's a slap in the face, 00:00:32 but in today's video, we'll find out what makes GROC special, how they trained it, 00:00:36 and if it truly is the best LLM in the world. 00:00:38 It is February 18, 2025, and you're watching The Code Report. 00:00:42 The last week, Elon attempted to troll Open AI by offering to buy it out. 00:00:46 Not surprisingly, the Open AI board promptly rejected this offer, 00:00:49 and Sam Altman is still on track to make it for profit and get his big payday. 00:00:52 The AI Game of Thrones is ruthless and Mark Zuckerberg one of the big players vying for the throne took a big loss last week when it was revealed that he signed off on using 82 terabytes of pirated books to train their llama models which he obtained through the Library Genesis Project which contains millions of books and paywall articles 00:01:08 I just can't believe Zuckerbucks would do something like that, though, said nobody ever. 00:01:12 When it comes to training AI, though, one thing that's special about GROC is that it's the only model that has direct access to the fire hose of data from Twitter. 00:01:19 And ex-AI developers have optimized this model for maximum truth-seeking, even if that comes at the expense of being politically correct. 00:01:26 means you can use it to do things like generate images of celebrities or have it write a profanity-laced 00:01:30 poem about racial stereotypes. In the name of science, I tried this prompt on every LLM and it was 00:01:35 blocked on every single one of them except for GROC. The response it gave me is so offensive that I 00:01:40 can't even show it here on YouTube, and if you posted something like this in a country that doesn't 00:01:44 have the right to free speech, you could quite literally go to jail. Despite that, GROC 3 should be 00:01:48 available in countries like Germany and the UK soon. That's a huge win if you're a professional 00:01:52 internet troll, but how good is GROC in reality? Well, currently, it's sitting on top 00:01:56 of LM Arena which is basically a blind taste test where humans compare different LLM side by side And reaching the top means that it pretty dang good In addition we have another benchmark showing Grock beating Gemini Claude Deep Seek and GPT4 00:02:08 when it comes to math science and coding. 00:02:10 However, conveniently, it's missing Open AI-O3, and when you add that model in, it paints a much 00:02:15 different picture. 00:02:15 It's also missing the code forces and ARC AGI benchmarks, and benchmarks are almost always cherry-picked 00:02:21 for obvious reasons. 00:02:22 The only thing I care about is my own proprietary vibe check, and it did things like Generate Valid's 00:02:26 five code in one shot and helped me build a game in Godot. 00:02:29 Overall, it did a great job and appears to be plateauing at the same level as all the other 00:02:33 state-of-the-art models. 00:02:35 Recently, the AI GRIPT is shifted from creating bigger, better base models to creating better 00:02:39 prompting frameworks like deep research and big brain mode. 00:02:42 Another interesting detail about GROC though is that they provided details on how it was 00:02:46 actually trained at the Colossus supercomputer in Memphis, Tennessee, which is currently 00:02:50 believed to be the world's largest AI supercomputer. 00:02:53 It contains a cluster of over 200,000 Nvidia H-100 G-GG. 00:02:56 with plans to expand to 1 million GPUs The facility uses so much electricity that they can get it all from the grid and brought in a bunch of portable diesel generators just to power the thing And they going to need all that power when SuperGrot comes out which is expected to cost per month which would 00:03:10 be a highly competitive price compared to ChatGPT Pro at $200 per month. As a developer, I'm already 00:03:16 going broke paying for Claude, Courser, Gemini, ChatGPT, co-pilot, Codium, Mid Journey, and WatsonX, 00:03:21 but for some reason my code quality is worse than ever. A better strategy to learn how to code is to 00:03:27 start from the ground up. And you can do that today for free, thanks to this video sponsor, 00:03:31 Brilliant. Their platform provides interactive hands-on lessons that demystify the complexity of deep 00:03:37 learning. With just a few minutes of effort each day, you can understand the math and computer 00:03:41 science behind the seemingly magic technology. I'd recommend starting with Python, then check out 00:03:46 their full how large language models work course if you really want to look under the hood of 00:03:50 chat GPT. Try everything Brilliant has to offer for free for 30 days by going to brilliant.org 00:03:57 or use the QR code on screen. 00:03:59 This has been the code report. 00:04:00 Thanks for watching and I will see you in the next one. 